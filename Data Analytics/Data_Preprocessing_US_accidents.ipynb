{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "data = pd.read_csv('dataset.csv',nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unecessary columns. These data are not helpful to our research\n",
    "data.drop('ID', axis=1, inplace=True)\n",
    "data.drop(\"Description\", axis=1, inplace=True)\n",
    "data.drop(\"Number\", axis=1, inplace=True)\n",
    "data.drop(\"Zipcode\", axis=1, inplace=True)\n",
    "data.drop(\"Country\", axis=1, inplace=True)\n",
    "data.drop(\"Airport_Code\", axis=1, inplace=True)\n",
    "data.drop(\"Weather_Timestamp\", axis=1, inplace=True)\n",
    "data.drop(\"Pressure(in)\", axis=1, inplace=True)\n",
    "data.drop(\"Wind_Direction\", axis=1, inplace=True)\n",
    "data.drop(\"Wind_Speed(mph)\", axis=1, inplace=True)\n",
    "data.drop(\"Precipitation(in)\", axis=1, inplace=True)\n",
    "data.drop(\"Amenity\", axis=1, inplace=True)\n",
    "data.drop(\"Bump\", axis=1, inplace=True)\n",
    "data.drop(\"Crossing\", axis=1, inplace=True)\n",
    "data.drop(\"Give_Way\", axis=1, inplace=True)\n",
    "data.drop(\"Junction\", axis=1, inplace=True)\n",
    "data.drop(\"No_Exit\", axis=1, inplace=True)\n",
    "data.drop(\"Railway\", axis=1, inplace=True)\n",
    "data.drop(\"Roundabout\", axis=1, inplace=True)\n",
    "data.drop(\"Station\", axis=1, inplace=True)\n",
    "data.drop(\"Stop\", axis=1, inplace=True)\n",
    "data.drop(\"Traffic_Calming\", axis=1, inplace=True)\n",
    "data.drop(\"Traffic_Signal\", axis=1, inplace=True)\n",
    "data.drop(\"Turning_Loop\", axis=1, inplace=True)\n",
    "data.drop(\"Start_Time\", axis=1, inplace=True)\n",
    "data.drop(\"End_Time\", axis=1, inplace=True)\n",
    "data.drop(\"Start_Lat\", axis=1, inplace=True)\n",
    "data.drop(\"Start_Lng\", axis=1, inplace=True)\n",
    "data.drop(\"End_Lat\", axis=1, inplace=True)\n",
    "data.drop(\"End_Lng\", axis=1, inplace=True)\n",
    "data.drop(\"Wind_Chill(F)\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete missing values\n",
    "# We will remove every row that has at least one missing value (NaN)\n",
    "data.dropna(axis=0,inplace=True)\n",
    "\n",
    "# Delete duplicate rows\n",
    "data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex the dataframe after deletion of rows\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the last 4 columns from the dataset\n",
    "last_4_columns  = data.iloc[: , -4:]\n",
    "\n",
    "# convert each record of these columns. Night == 0 and Day == 1\n",
    "last_4_columns[\"Sunrise_Sunset\"] = np.where(last_4_columns[\"Sunrise_Sunset\"] == \"Night\", 0, 1)\n",
    "last_4_columns[\"Civil_Twilight\"] = np.where(last_4_columns[\"Civil_Twilight\"] == \"Night\", 0, 1)\n",
    "last_4_columns[\"Nautical_Twilight\"] = np.where(last_4_columns[\"Nautical_Twilight\"] == \"Night\", 0, 1)\n",
    "last_4_columns[\"Astronomical_Twilight\"] = np.where(last_4_columns[\"Astronomical_Twilight\"] == \"Night\", 0, 1)\n",
    "\n",
    "# find the mean of each row of the last_4_columns dataframe\n",
    "last_4_columns = last_4_columns.mean(axis=1)\n",
    "\n",
    "# convert the values of the last_4_rows dataframe into 0 and 1, based in a condition\n",
    "# if the mean of a row is <0,5, then the value of this row will be 0, else it will be 1\n",
    "for i in range (len(last_4_columns)):\n",
    "    if last_4_columns[i] < 0.5:\n",
    "        last_4_columns[i] = 0\n",
    "    else:\n",
    "        last_4_columns[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert R and L to 0 and 1 respectively. That means that R is 0 and L is 1.\n",
    "data[\"Side\"] = np.where(data['Side'] == \"R\", 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the last 4 columns of the dataset\n",
    "# we do not need them, as we can combine them in a new column\n",
    "data.drop('Sunrise_Sunset', axis=1, inplace=True)\n",
    "data.drop('Civil_Twilight', axis=1, inplace=True)\n",
    "data.drop('Nautical_Twilight', axis=1, inplace=True)\n",
    "data.drop('Astronomical_Twilight', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column to the dataset.\n",
    "# this new column will be the \"last_4_columns\" dataframe that we calculated earlier\n",
    "data.insert(12,\"Day_Night\",last_4_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Columns Data Types\n",
    "\n",
    "# Converting Day_Night column from float to int\n",
    "data = data.astype({\"Day_Night\": int})\n",
    "\n",
    "# round all the values of \"Temperature(F)\" column\n",
    "data[\"Temperature(F)\"] = data[\"Temperature(F)\"].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete outliers from the dataset using the IQR method.\n",
    "# We will focus only in columns: Temperature(F), Distance(mi) and Humidity(%)\n",
    "for x in [\"Temperature(F)\"]:\n",
    "    q75,q25 = np.percentile(data.loc[:,x],[75,25])\n",
    "    intr_qr = q75-q25\n",
    "\n",
    "    max = q75+(1.5*intr_qr)\n",
    "    min = q25-(1.5*intr_qr)\n",
    "\n",
    "    data.loc[data[x] < min,x] = np.nan\n",
    "    data.loc[data[x] > max,x] = np.nan\n",
    "\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "for x in [\"Distance(mi)\"]:\n",
    "    q75,q25 = np.percentile(data.loc[:,x],[75,25])\n",
    "    intr_qr = q75-q25\n",
    "\n",
    "    max = q75+(1.5*intr_qr)\n",
    "    min = q25-(1.5*intr_qr)\n",
    "\n",
    "    data.loc[data[x] < min,x] = np.nan\n",
    "    data.loc[data[x] > max,x] = np.nan\n",
    "\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "for x in [\"Humidity(%)\"]:\n",
    "    q75,q25 = np.percentile(data.loc[:,x],[75,25])\n",
    "    intr_qr = q75-q25\n",
    "\n",
    "    max = q75+(1.5*intr_qr)\n",
    "    min = q25-(1.5*intr_qr)\n",
    "\n",
    "    data.loc[data[x] < min,x] = np.nan\n",
    "    data.loc[data[x] > max,x] = np.nan\n",
    "\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "for x in [\"Visibility(mi)\"]:\n",
    "    q75,q25 = np.percentile(data.loc[:,x],[75,25])\n",
    "    intr_qr = q75-q25\n",
    "\n",
    "    max = q75+(1.5*intr_qr)\n",
    "    min = q25-(1.5*intr_qr)\n",
    "\n",
    "    data.loc[data[x] < min,x] = np.nan\n",
    "    data.loc[data[x] > max,x] = np.nan\n",
    "\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "# Delete rows that contain nulls (outliers)\n",
    "data.dropna(axis=0,inplace=True)\n",
    "\n",
    "# reindex the dataframe after deletion of rows\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretization of the column \"Weather_Condition\"\n",
    "\n",
    "# we have separated all unique weather conditions of the dataset into three lists (bad_weather,medium_weather and perfect_weather).\n",
    "# This separation has been done according to our opinion.\n",
    "bad_weather = ['Patches of Fog','Haze','Smoke','Light Snow','Snow Grains','Squalls','Shallow Fog','Thunderstorm','Light Ice Pellets','Light Thunderstorms and Rain','Thunder','Thunder in the Vicinity','Thunderstorms and Rain',\n",
    "'Heavy Rain','Widespread Dust','Blowing Dust / Windy','Blowing Snow','Tornado','Light Snow / Windy','Fog','Mist','Light Snow Showers','T-Storm','T-Storm / Windy','Wintry Mix','Volcanic Ash','Light Rain with Thunder',\n",
    "'Heavy Thunderstorms and Rain', 'Haze / Windy',\n",
    "'Dust Whirls','Light Snow and Sleet','Thunder / Windy','Snow','Heavy T-Storm / Windy','Heavy T-Storm','Light Snow and Sleet / Windy','Heavy Drizzle',\n",
    "'Light Sleet','Sand / Dust Whirlwinds','Patches of Fog / Windy','Low Drifting Snow','Blowing Snow Nearby','Heavy Rain / Windy','Squalls / Windy','Sand / Dust Whirls Nearby',\n",
    "'Wintry Mix / Windy','Sleet']\n",
    "\n",
    "medium_weather = ['Light Rain','Overcast','Mostly Cloudy', 'Cloudy','Scattered Clouds','Drizzle','Light Drizzle','Light Freezing Drizzle','Rain','Fair / Windy','Light Freezing Rain','Cloudy / Windy','Partly Cloudy / Windy',\n",
    "'Light Rain Showers','Light Rain / Windy','Mostly Cloudy / Windy','Blowing Dust','Funnel Cloud','Light Rain Shower','Smoke / Windy','Light Rain Shower / Windy','Rain Shower','Sand / Dust Whirlwinds / Windy','Rain Showers',\n",
    "'Light Drizzle / Windy','Showers in the Vicinity','Widespread Dust / Windy','Light Freezing Rain / Windy''N/A Precipitation','Rain / Windy',\n",
    "'Light Sleet / Windy','Hail','Drizzle / Windy','Light Haze']\n",
    "\n",
    "perfect_weather = ['Clear','Fair','Partly Cloudy','Small Hail']\n",
    "\n",
    "# change the values of the column \"Weather_Condition\" column\n",
    "# Now, column \"Weather_Condition\" has only records: \"Bad\",\"Medium\" and \"Perfect\"\n",
    "for i in range(len(data[\"Weather_Condition\"])):\n",
    "    if data[\"Weather_Condition\"][i] in bad_weather:\n",
    "        data.at[i,\"Weather_Condition\"] = \"Bad\"\n",
    "\n",
    "    elif data[\"Weather_Condition\"][i] in medium_weather:\n",
    "        data.at[i,\"Weather_Condition\"] = \"Medium\"\n",
    "    else:\n",
    "         data.at[i,\"Weather_Condition\"] = \"Perfect\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6fb58d5bbdf3e84a85f0ae94f751a2c3cf07e38a9cfa360064b5bdbc8f825c4e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Data_Analytics_6th_Peek')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
