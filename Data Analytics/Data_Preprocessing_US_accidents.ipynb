{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2845342, 47)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataset\n",
    "data = pd.read_csv('dataset.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unecessary columns. These data are not helpful to our research\n",
    "data.drop('ID', axis=1, inplace=True)\n",
    "data.drop(\"Description\", axis=1, inplace=True)\n",
    "data.drop(\"Number\", axis=1, inplace=True)\n",
    "data.drop(\"Zipcode\", axis=1, inplace=True)\n",
    "data.drop(\"Country\", axis=1, inplace=True)\n",
    "data.drop(\"Airport_Code\", axis=1, inplace=True)\n",
    "data.drop(\"Weather_Timestamp\", axis=1, inplace=True)\n",
    "data.drop(\"Pressure(in)\", axis=1, inplace=True)\n",
    "data.drop(\"Wind_Direction\", axis=1, inplace=True)\n",
    "data.drop(\"Wind_Speed(mph)\", axis=1, inplace=True)\n",
    "data.drop(\"Precipitation(in)\", axis=1, inplace=True)\n",
    "data.drop(\"Amenity\", axis=1, inplace=True)\n",
    "data.drop(\"Bump\", axis=1, inplace=True)\n",
    "data.drop(\"Crossing\", axis=1, inplace=True)\n",
    "data.drop(\"Give_Way\", axis=1, inplace=True)\n",
    "data.drop(\"Junction\", axis=1, inplace=True)\n",
    "data.drop(\"No_Exit\", axis=1, inplace=True)\n",
    "data.drop(\"Railway\", axis=1, inplace=True)\n",
    "data.drop(\"Roundabout\", axis=1, inplace=True)\n",
    "data.drop(\"Station\", axis=1, inplace=True)\n",
    "data.drop(\"Stop\", axis=1, inplace=True)\n",
    "data.drop(\"Traffic_Calming\", axis=1, inplace=True)\n",
    "data.drop(\"Traffic_Signal\", axis=1, inplace=True)\n",
    "data.drop(\"Turning_Loop\", axis=1, inplace=True)\n",
    "data.drop(\"Start_Time\", axis=1, inplace=True)\n",
    "data.drop(\"End_Time\", axis=1, inplace=True)\n",
    "data.drop(\"Start_Lat\", axis=1, inplace=True)\n",
    "data.drop(\"Start_Lng\", axis=1, inplace=True)\n",
    "data.drop(\"End_Lat\", axis=1, inplace=True)\n",
    "data.drop(\"End_Lng\", axis=1, inplace=True)\n",
    "data.drop(\"Wind_Chill(F)\", axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete missing values\n",
    "# We will remove every row that has at least one missing value (NaN)\n",
    "data.dropna(axis=0,inplace=True)\n",
    "\n",
    "# Delete duplicate rows\n",
    "data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex the dataframe after deletion of rows\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the last 4 columns from the dataset\n",
    "last_4_columns  = data.iloc[: , -4:]\n",
    "\n",
    "# convert each record of these columns. Night == 0 and Day == 1\n",
    "last_4_columns[\"Sunrise_Sunset\"] = np.where(last_4_columns[\"Sunrise_Sunset\"] == \"Night\", 0, 1)\n",
    "last_4_columns[\"Civil_Twilight\"] = np.where(last_4_columns[\"Civil_Twilight\"] == \"Night\", 0, 1)\n",
    "last_4_columns[\"Nautical_Twilight\"] = np.where(last_4_columns[\"Nautical_Twilight\"] == \"Night\", 0, 1)\n",
    "last_4_columns[\"Astronomical_Twilight\"] = np.where(last_4_columns[\"Astronomical_Twilight\"] == \"Night\", 0, 1)\n",
    "\n",
    "# find the mean of each row of the last_4_columns dataframe\n",
    "last_4_columns = last_4_columns.mean(axis=1)\n",
    "\n",
    "# convert the values of the last_4_rows dataframe into 0 and 1, based in a condition\n",
    "# if the mean of a row is <0,5, then the value of this row will be 0, else it will be 1\n",
    "for i in range (len(last_4_columns)):\n",
    "    if last_4_columns[i] < 0.5:\n",
    "        last_4_columns[i] = 0\n",
    "    else:\n",
    "        last_4_columns[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the last 4 columns of the dataset\n",
    "# we do not need them, as we can combine them in a new column\n",
    "data.drop('Sunrise_Sunset', axis=1, inplace=True)\n",
    "data.drop('Civil_Twilight', axis=1, inplace=True)\n",
    "data.drop('Nautical_Twilight', axis=1, inplace=True)\n",
    "data.drop('Astronomical_Twilight', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2476470, 13)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a new column to the dataset.\n",
    "# this new column will be the \"last_4_columns\" dataframe that we calculated earlier\n",
    "data.insert(12,\"Day_Night\",last_4_columns)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Light Rain', 'Overcast', 'Mostly Cloudy', 'Snow', 'Light Snow',\n",
       "       'Cloudy', 'Scattered Clouds', 'Clear', 'Partly Cloudy',\n",
       "       'Light Freezing Drizzle', 'Light Drizzle', 'Haze', 'Rain',\n",
       "       'Heavy Rain', 'Fair', 'Drizzle', 'Fog', 'Thunderstorms and Rain',\n",
       "       'Patches of Fog', 'Light Thunderstorms and Rain', 'Mist',\n",
       "       'Rain Showers', 'Light Rain Showers', 'Heavy Drizzle', 'Smoke',\n",
       "       'Light Freezing Fog', 'Light Freezing Rain', 'Blowing Snow',\n",
       "       'Heavy Thunderstorms and Rain', 'Heavy Snow', 'Snow Grains',\n",
       "       'Squalls', 'Light Fog', 'Shallow Fog', 'Thunderstorm',\n",
       "       'Light Ice Pellets', 'Thunder', 'Thunder in the Vicinity',\n",
       "       'Fair / Windy', 'Light Rain with Thunder',\n",
       "       'Heavy Thunderstorms and Snow', 'Light Snow Showers',\n",
       "       'Cloudy / Windy', 'Ice Pellets', 'N/A Precipitation',\n",
       "       'Light Thunderstorms and Snow', 'T-Storm', 'Rain / Windy',\n",
       "       'Wintry Mix', 'Partly Cloudy / Windy', 'Heavy T-Storm',\n",
       "       'Light Rain / Windy', 'Widespread Dust', 'Mostly Cloudy / Windy',\n",
       "       'Blowing Dust / Windy', 'Blowing Dust', 'Volcanic Ash',\n",
       "       'Freezing Rain / Windy', 'Small Hail', 'Wintry Mix / Windy',\n",
       "       'Light Snow / Windy', 'Heavy Ice Pellets', 'Heavy Snow / Windy',\n",
       "       'Heavy Rain / Windy', 'Heavy T-Storm / Windy', 'Fog / Windy',\n",
       "       'Dust Whirls', 'Showers in the Vicinity', 'Funnel Cloud',\n",
       "       'Thunder / Windy', 'Snow / Windy', 'Haze / Windy',\n",
       "       'Light Snow and Sleet', 'T-Storm / Windy',\n",
       "       'Sand / Dust Whirlwinds', 'Light Snow with Thunder', 'Rain Shower',\n",
       "       'Blowing Snow / Windy', 'Light Rain Shower', 'Snow and Sleet',\n",
       "       'Drizzle and Fog', 'Light Sleet', 'Drizzle / Windy',\n",
       "       'Light Snow Shower', 'Snow and Thunder / Windy',\n",
       "       'Light Sleet / Windy', 'Smoke / Windy', 'Widespread Dust / Windy',\n",
       "       'Light Drizzle / Windy', 'Tornado', 'Squalls / Windy', 'Hail',\n",
       "       'Blowing Snow Nearby', 'Partial Fog', 'Sand / Windy',\n",
       "       'Thunder / Wintry Mix', 'Light Freezing Rain / Windy', 'Duststorm',\n",
       "       'Light Snow and Sleet / Windy', 'Heavy Rain Shower / Windy',\n",
       "       'Sand / Dust Whirlwinds / Windy', 'Light Rain Shower / Windy',\n",
       "       'Thunder and Hail', 'Freezing Rain', 'Heavy Sleet', 'Sleet',\n",
       "       'Freezing Drizzle', 'Snow and Sleet / Windy',\n",
       "       'Heavy Freezing Drizzle', 'Heavy Freezing Rain', 'Blowing Sand',\n",
       "       'Thunder / Wintry Mix / Windy', 'Sleet / Windy',\n",
       "       'Patches of Fog / Windy', 'Sand / Dust Whirls Nearby',\n",
       "       'Heavy Rain Shower', 'Drifting Snow', 'Heavy Blowing Snow',\n",
       "       'Low Drifting Snow', 'Light Blowing Snow', 'Heavy Rain Showers',\n",
       "       'Light Haze', 'Heavy Thunderstorms with Small Hail',\n",
       "       'Heavy Snow with Thunder', 'Thunder and Hail / Windy'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change Columns Data Types\n",
    "\n",
    "#Converting Day_Night column from float to int\n",
    "data = data.astype({\"Day_Night\": int})\n",
    "\n",
    "#To Be Deleted Shows The Values Of different weather\n",
    "data[\"Weather_Condition\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2223463, 13)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete outliers from the dataset using the IQR method.\n",
    "# We will focus only in columns: Temperature(F), Distance(mi) and Humidity(%)\n",
    "\n",
    "for x in [\"Temperature(F)\"]:\n",
    "    q75,q25 = np.percentile(data.loc[:,x],[75,25])\n",
    "    intr_qr = q75-q25\n",
    "\n",
    "    max = q75+(1.5*intr_qr)\n",
    "    min = q25-(1.5*intr_qr)\n",
    "\n",
    "    data.loc[data[x] < min,x] = np.nan\n",
    "    data.loc[data[x] > max,x] = np.nan\n",
    "\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "for x in [\"Distance(mi)\"]:\n",
    "    q75,q25 = np.percentile(data.loc[:,x],[75,25])\n",
    "    intr_qr = q75-q25\n",
    "\n",
    "    max = q75+(1.5*intr_qr)\n",
    "    min = q25-(1.5*intr_qr)\n",
    "\n",
    "    data.loc[data[x] < min,x] = np.nan\n",
    "    data.loc[data[x] > max,x] = np.nan\n",
    "\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "for x in [\"Humidity(%)\"]:\n",
    "    q75,q25 = np.percentile(data.loc[:,x],[75,25])\n",
    "    intr_qr = q75-q25\n",
    "\n",
    "    max = q75+(1.5*intr_qr)\n",
    "    min = q25-(1.5*intr_qr)\n",
    "\n",
    "    data.loc[data[x] < min,x] = np.nan\n",
    "    data.loc[data[x] > max,x] = np.nan\n",
    "\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "# Delete rows that contain nulls (outliers)\n",
    "data.dropna(axis=0,inplace=True)\n",
    "\n",
    "# reindex the dataframe after deletion of rows\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6fb58d5bbdf3e84a85f0ae94f751a2c3cf07e38a9cfa360064b5bdbc8f825c4e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Data_Analytics_6th_Peek')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
